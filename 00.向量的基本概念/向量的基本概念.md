

# 向量的基本概念，其实没你想的那么难

## 先从一个最简单的问题说起

我发现很多人一听到"向量"两个字就头大，觉得这是个特别抽象的数学概念。但说实话，你每天都在跟向量打交道，只是你没意识到而已。

举个例子，你跟朋友说"往前走100米"，你朋友大概率会问你一句，往哪个方向走？这就对了。光说100米是不够的，得告诉他方向。100米是大小，往北走是方向，这两个信息合在一起，就构成了一个向量。

再比如风速，气象预报说今天风力5级，这只是一个数字，在数学里我们叫它**标量**。但如果说"东北风5级"，有了方向有了大小，这就变成了一个向量。

所以向量这个东西，一句话就能讲明白，**既有大小又有方向的量，就是向量**。只有大小没有方向的，比如温度、质量、年龄，那叫标量。这两者的区别就这么直接。

---

## 向量长什么样

理解了向量是什么之后，下一个问题自然就来了，我们怎么把它表示出来？

**最直观的方式就是画一个箭头。** 箭头的长度代表向量的大小，箭头指的方向代表向量的方向。你在物理课本上见过的那些力的分析图，满页都是箭头，其实画的全是向量。

```
        ↗ B
       /
      /  这个箭头就是一个向量
     /   长度 = 大小（模）
    /    方向 = A指向B
   A
```

但是你想啊，画箭头这种方式太感性了，没法精确计算。我告诉你这个箭头大概指向右上方，你能精确地知道它到底偏了多少度吗？很难。所以我们需要一种更精确的表示方法，那就是**坐标表示**。

在一个平面坐标系里，一个向量可以用两个数字来表示，比如 **(3, 4)**。第一个数字3表示在x轴方向上走了3个单位，第二个数字4表示在y轴方向上走了4个单位。

```
  y
  ↑
  4 ┤· · · · ·➤ (3,4)
  3 ┤· · · ·／
  2 ┤· · ·／
  1 ┤· ·／
  0 ┼─┬─┬─┬─→ x
    0  1  2  3
```

这样一来，每个向量都变成了一组确定的数字，计算起来就方便多了。向量的大小也能直接算出来，(3, 4) 这个向量的大小就是 √(3² + 4²) = 5，这个你初中学勾股定理的时候就会了。

如果是在三维空间里，一个向量就用三个数字表示，比如 **(1, 2, 3)**，分别对应x、y、z三个方向上的分量。到这里都还很好理解，因为我们生活在三维世界，脑子里想得出来。

---

## 当维度突破想象力的边界

接下来这部分是我觉得最有意思的地方。

二维向量有两个数字，三维向量有三个数字，那如果我搞一个有768个数字的向量呢？这就是768维向量。听起来很疯狂对吧，768维的空间长什么样？老实说，谁也想象不出来。但数学的魅力就在这里，**你不需要想象得出来，你只需要会算就行**。

从数学的角度看，一个n维向量就是一个包含n个数字的有序列表，

```
二维向量，  (x₁, x₂)
三维向量，  (x₁, x₂, x₃)
n维向量，   (x₁, x₂, x₃, ..., xₙ)
```

二维和七百多维在计算规则上没有任何本质区别，加法还是对应位置相加，求大小还是各分量平方和再开根号。只不过数字多了几百个而已。

你可能会问，搞这么高的维度有什么用？用处太大了。

在当下最火的AI领域，大语言模型就是把每个词、每句话转换成高维向量来处理的。OpenAI的嵌入模型会把一段文字变成一个1536维的向量，Google的一些模型用的是768维。这些高维向量能捕捉到文字之间非常微妙的语义关系，比如"国王"和"王后"的向量会比较接近，"猫"和"狗"的向量也会比较接近，但"猫"和"经济学"的向量就差得很远。

我用Python简单演示一下，让你感受感受高维向量到底长什么样，

```python
import numpy as np

# 一个普通的二维向量
vec_2d = np.array([3, 4])
print(f"二维向量, {vec_2d}")
print(f"大小, {np.linalg.norm(vec_2d)}")  # 输出 5.0

# 一个三维向量
vec_3d = np.array([1, 2, 3])
print(f"三维向量, {vec_3d}")
print(f"大小, {np.linalg.norm(vec_3d)}")  # 输出 3.7416...

# 模拟一个768维的向量（类似AI模型输出的嵌入向量）
vec_768d = np.random.randn(768)
print(f"768维向量的前10个分量, {vec_768d[:10]}")
print(f"768维向量的大小, {np.linalg.norm(vec_768d)}")

# 你看，不管多少维，求大小的方式完全一样
```

运行这段代码你会发现，768维向量就是一长串浮点数，每个数字就是一个维度上的分量。计算规则和二维向量一模一样，无非是循环多跑几百次。

---

## 什么时候两个向量是相等的

最后聊一个看起来简单但其实很重要的问题，两个向量什么时候算相等？

条件只有一个，**对应分量全部相等**。

拿二维向量举例，向量 (3, 4) 和向量 (3, 4) 相等。但向量 (3, 4) 和向量 (4, 3) 就不相等，虽然数字是一样的，但位置换了，意味着方向不同。

放到高维空间也是一样的道理。两个768维的向量要相等，768个分量必须一一对应全部相同，差一个都不行。

```python
a = np.array([1, 2, 3])
b = np.array([1, 2, 3])
c = np.array([1, 3, 2])

print(np.array_equal(a, b))  # True，每个分量都对应相等
print(np.array_equal(a, c))  # False，第二个和第三个分量对不上
```

这里还有一个特别容易搞混的点，向量的相等跟它的起点位置无关。在几何上，你把一个箭头从原点平移到其他位置，只要长度和方向不变，它依然是同一个向量。这种向量叫做自由向量，我们平时讨论的绝大多数向量都是这种。

---

## 最后帮你把脉络理一理

下面这张思维导图把今天讲的内容串了起来，建议你对着它回顾一遍，

```
                    ┌─ 标量，只有大小（温度、质量）
       ┌─ 基本区分 ─┤
       │            └─ 向量，大小 + 方向（力、速度、位移）
       │
       │            ┌─ 几何表示，箭头（直观但不精确）
       ├─ 表示方法 ─┤
       │            └─ 坐标表示，有序数组（精确可计算）
向量 ──┤
       │            ┌─ 2D，(x, y)
       │            ├─ 3D，(x, y, z)
       ├─ 维度扩展 ─┤
       │            ├─ 768D，AI文本嵌入
       │            └─ 1536D，OpenAI嵌入模型
       │
       │            ┌─ 对应分量全部相等
       └─ 相等条件 ─┤
                    └─ 与起点位置无关（自由向量）
```

说到底，向量这个概念本身真的不复杂。你就把它理解成一组有顺序的数字，这组数字描述了某个方向上的某种量。二维三维我们能画出来看得见，更高的维度虽然看不见，但数学规则完全通用。把这个根基打扎实了，后面学向量的加减法、点积、叉积，甚至搞AI里的向量检索，都会顺畅很多。
